{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1mjSR3AtA3TdCwt5zllte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tincorpai/Deep_Learning_Pytorch/blob/master/PyTorch_Custom_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is a custom dataset?"
      ],
      "metadata": {
        "id": "AK_TUnQsmdSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've used some datasets with PyToch before. But how can you get your own data into PyTorch?\n",
        "\n",
        "One of the ways to do so is via Custom datasets.\n",
        "\n",
        "Depending on what you're working on, vision, text, audio, recommendation, you'll want to look into each of the PyTorch domain libraries for existing data loading functions and customizable data loading functions.\n",
        "\n",
        "**Resources:** https://www.learnpytorch.io/04_pytorch_custom_datasets/\n",
        "\n",
        "**Dataset Creation code** https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb"
      ],
      "metadata": {
        "id": "JnbNbnXTdUWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Domain Libraries \n",
        "\n",
        "|Problem Space         |  Pre-build Datasets and Functions|\n",
        "----------------------- |----------------------------------|\n",
        "| Vision               |    torchvision.datasets           |\n",
        "|Text                  |   torchtext.datsets               |\n",
        "|Audio                 |   torchaudio.datasets             |\n",
        "|Recommendation system |   torchrec.datasets               |\n",
        "|Bonus                 |   TorchData*                      |\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQAOW4fKpUO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Custom Datasets\n",
        "\n",
        "*  Getting a custom dataset with PyTorch\n",
        "\n",
        "*  Becoming one with the data (preparing and visualizing)\n",
        "\n",
        "*  Transforming data for use with a model\n",
        "\n",
        "*  Loaing custom data with pre-built functions and custom functions.\n",
        "\n",
        "*  Building FoodVision Mini to classify images\n",
        "\n",
        "*  Comparing models with and without data augmentation\n",
        "\n",
        "*  Making predictions on custom data (data not within our training or testing dataset."
      ],
      "metadata": {
        "id": "g8z6n5u9qirY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0. Importing PyTorch and setting up device-agnostic code."
      ],
      "metadata": {
        "id": "QBWssZvKs1UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: PyTorch 1.10.0+ is required for this course (Check the version of PyTorch)\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7Y8NaNpMvFas",
        "outputId": "539398cc-3989-40e2-803c-dd239c693a43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H9wQW1ouvs7b",
        "outputId": "0b299057-e269-4add-9c7f-26bb004dead0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Get Dataset\n",
        "\n",
        "Our dataset is a subset of Food101 dataset.\n",
        "\n",
        "Food101 starts with 101 different classes of food and 1000 images per class 750 training, 250 testing).\n",
        "\n",
        "Our dataset starts with 3 classes of food and only 10% of the images (~75 training, 25 testing).\n",
        "\n",
        "Why do this?\n",
        "\n",
        "\n",
        "When starting out ML projects, it's important to try things on a small scale and then increae the scale when necessary.\n",
        "\n",
        "the whole point is to speed up how fast you can experiment.\n"
      ],
      "metadata": {
        "id": "Gh4gabeVv7a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "#Setup path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "#if the image folder doesn't exist, download it and prepare it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists... skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "#Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Download pizza, steak, sushi, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "#unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza, steak, sushi data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQzQ5C62zlUY",
        "outputId": "599eaf47-ae3d-4486-a119-4ab3ca1204ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists... skipping download\n",
            "Download pizza, steak, sushi, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Understanding the dataset (data preparation and data exploration)"
      ],
      "metadata": {
        "id": "2Ksx83Z65i0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"
      ],
      "metadata": {
        "id": "l5uUGOmv5uwr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTW3-0mH7BUV",
        "outputId": "5700b035-e9f9-409b-90fc-defb59a34cff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
            "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
            "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n",
            "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
            "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
            "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
            "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Image Classification Data Format\n",
        "\n"
      ],
      "metadata": {
        "id": "HbkVtgAo7yt_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gIeVMY5O9JQm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}